# @schema
# description: User should be specifying the signals they want to collect.
# @schema
signals:
  - traces
  - metrics
  - logs

image:
  tag: ''
imagePullSecrets: []

# @schema
# description: |-
#   By default, images are pulled from odigos registry at `registry.odigos.io`
#   If you use custom or internal registry to serve in your cluster, you can set the imagePrefix to your registry.
#   For example, if you set imagePrefix to `myregistry.io/odigos`, the images will be pulled from `myregistry.io/odigos/odigos-<component>:<tag>`
# @schema
imagePrefix:

# @schema
# description: |-
#   Per-component image overrides. When set, these full image URLs take precedence over
#   the constructed image name (imagePrefix + component + tag).
#   This is primarily used by the OpenShift operator with RELATED_IMAGE_* env vars.
#   Example:
#     images:
#       autoscaler: registry.connect.redhat.com/odigos/odigos-autoscaler-ubi9:v1.0.0
#       collector: registry.connect.redhat.com/odigos/odigos-collector-ubi9:v1.0.0
#   Supported component names: autoscaler, collector, ui, instrumentor, enterprise-instrumentor,
#     odiglet, enterprise-odiglet, scheduler, agents, enterprise-agents
# @schema
images: {}

# @schema
# description: |-
#   namespaces list not to show in odigos ui
#   set by default: odigos-system, kube-system, local-path-storage, istio-system, linkerd, kube-node-lease
#   you can add additional namespaces to ignore by adding them to the list
# @schema
ignoredNamespaces:

# @schema
# description: |-
#   Whether to automatically ignore the namespace where Odigos is installed.
#   By default (true), the Odigos namespace is automatically added to ignoredNamespaces.
#   Set to false to allow the Odigos namespace to be visible in the UI.
#   Default: true
# @schema
ignoreOdigosNamespace: true

# @schema
# description: |-
#   container names to never instrument
#   useful for sidecars which are not interesting to be instrumented
#   set by default: istio-proxy, vault-agent, filebeat, linkerd-proxy, fluentd, akeyless-init
#   you can add additional container names to ignore by adding them to the list
# @schema
ignoredContainers:

# @schema
# description: Name of the cluster, will be used to identify this cluster in the centralized backend
# @schema
clusterName: ''

# @schema
# description: Configuration for OpenTelemetry (OTEL) agents instrumentation environment variables.
# @schema
userInstrumentationEnvs:
  # @schema
  # description: |-
  #   Configuration for OpenTelemetry (OTEL) agents instrumentation.
  #   These settings enable and configure OTEL agents for programming languages supported by Odigos.
  #   See the official OTEL documentation for language-specific configuration details:
  #   https://opentelemetry.io/docs/zero-code/
  #   Example:
  #   languages:
  #     java:
  #       enabled: true
  #       env:
  #         OTEL_INSTRUMENTATION_COMMON_EXPERIMENTAL_VIEW_TELEMETRY_ENABLED: "true"
  #   Note: For eBPF-based distributions, exporting and batching cannot be configured here, as they are managed by the Odiglet.
  #   Warning: This is an advanced feature. Only modify these settings if you are familiar with OTEL and its implications.
  # @schema
  languages:
    java:
      enabled: false
      env: {}
    python:
      enabled: false
      env: {}
    nodejs:
      enabled: false
      env: {}
    go:
      enabled: false
      env: {}
    dotnet:
      enabled: false
      env: {}
    php:
      enabled: false
      env: {}

# @schema
# description: |-
#   Sizing Configurations size_s, size_m, size_l are pre-defined configurations designed to simplify pipeline configurations.
#   The default value is 'size_m', which is the medium size configuration.
#   See https://docs.odigos.io/pipeline/configuration#1-using-sizing-configuration for more details.
# @schema
ResourceSizePreset: size_m

# @schema
# description: |-
#   HYBRID CONFIGURATION APPROACH:
#   By default, all values below are automatically set based on the ResourceSizePreset above.
#   Uncomment and modify any value to override the automatic sizing for that specific parameter.
#   
#   IMPORTANT CONSTRAINTS:
#   1. minReplicas must be less or equal to maxReplicas
#   2. If you set limitMemoryMiB without requestMemoryMiB, request will equal limit
#   3. If you set requestMemoryMiB without limitMemoryMiB, limit will equal request
#   4. Same logic applies to CPU settings
# @schema
collectorGateway:
  # @schema
  # description: |-
  #   Service Graph settings
  #   Service Graph is a feature that allows you to visualize the service graph of your application.
  #   It is enabled by default and can be disabled by setting the disabled flag to true.
  # @schema
  serviceGraphDisabled: false

  # @schema
  # description: |-
  #   Cluster Metrics settings
  #   Cluster Metrics is a feature that allows you to enable the cluster metrics.
  #   [https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/receiver/k8sclusterreceiver]
  #   It is disabled by default and can be enabled by setting the enabled flag to true.
  # @schema
  clusterMetricsEnabled: false

  # @schema
  # description: |-
  #   the memory request for the cluster gateway collector deployment.
  #   it will be embedded in the deployment as a resource request
  #   of the form "memory: <value>Mi".
  #   default value is 500Mi
  #   If you set only requestMemoryMiB, the limitMemoryMiB will be set to the same value.
  # @schema
  # requestMemoryMiB: 625

  # @schema
  # description: |-
  #   the memory limit for the cluster gateway collector deployment.
  #   it will be embedded in the deployment as a resource limit
  #   of the form "memory: <value>Mi".
  #   default value is 625Mi
  #   If you set only limitMemoryMiB, the requestMemoryMiB will be set to the same value.
  # @schema
  # limitMemoryMiB: 625

  # @schema
  # description: |-
  #   the CPU request for the cluster gateway collector deployment.
  #   it will be embedded in the deployment as a resource request
  #   of the form "cpu: <value>m".
  #   default value is 500m
  #   If you set only requestCPUm, the limitCPUm will be set to the same value.
  # @schema
  # requestCPUm: 500

  # @schema
  # description: |-
  #   the CPU limit for the cluster gateway collector deployment.
  #   it will be embedded in the deployment as a resource limit
  #   of the form "cpu: <value>m".
  #   default value is 1000m
  #   If you set only limitCPUm, the requestCPUm will be set to the same value.
  # @schema
  # limitCPUm: 1000

  # @schema
  # description: |-
  #   The number of replicas for the cluster gateway collector deployment.
  #   Also uses in MinReplicas the HPA config.
  # @schema
  # minReplicas: 1

  # @schema
  # description: The maxReplicas in the HPA config.
  # @schema
  # maxReplicas: 10

  # @schema
  # description: |-
  #   sets the "limit_mib" parameter in the memory limiter configuration for the collector gateway.
  #   it is the hard limit after which a force garbage collection will be performed.
  #   if not set, it will be 50Mi below the memory limit.
  # @schema
  # memoryLimiterLimitMiB: 575

  # @schema
  # description: |-
  #   sets the "spike_limit_mib" parameter in the memory limiter configuration for the collector gateway.
  #   note that this is not the processor soft limit, but the diff in MiB between the hard limit and the soft limit.
  #   if not specified, this value will be set to 20% of the hard limit (so the soft limit will be 80% of the hard limit).
  # @schema
  # memoryLimiterSpikeLimitMiB: 110

  # @schema
  # description: |-
  #   the GOMEMLIMIT environment variable value for the collector gateway deployment.
  #   this is when go runtime will start garbage collection.
  #   if not specified, it will be set to 80% of the hard limit of the memory limiter.
  # @schema
  # goMemLimitMiB: 460

  # @schema
  # description: |-
  #   for destinations that uses https for exporting data, this value can be used to set the address for an https proxy.
  #   when unset or empty, no proxy will be used.
  # @schema
  # httpsProxyAddress: ''


  # @schema
  # description: |-
  #   Node selector for the cluster gateway collector deployment.
  #   Uncomment to override the global nodeSelector (values.nodeSelector) for this component
  # @schema
  # nodeSelector:
  #   kubernetes.io/os: linux

# @schema
# description: Settings for Odigos data-collection (node) Collectors
# @schema
collectorNode:
  # @schema
  # description: |-
  #   The port to use for exposing the collector's own metrics as a prometheus endpoint.
  #   This can be used to resolve conflicting ports when a collector is using the host network.
  # @schema
  collectorOwnMetricsPort: 55682

  # @schema
  # description: |-
  #   this configuration is used for logs collection where '/var/log' in a k8s node is a symlink
  #   to some other directory (for example, '/mnt/var/log')
  # @schema
  k8sNodeLogsDirectory: ''

  # @schema
  # description: OTLP exporter configuration for the node collector.
  # @schema
  otlpExporterConfiguration:
    # @schema
    # description: |-
    #   EnableDataCompression is a feature that allows you to enable data compression before sending data to the Gateway collector.
    #   It is disabled by default and can be enabled by setting the enabled flag to true.
    # @schema
    enableDataCompression: false
    # @schema
    # description: Time to wait per individual attempt to send data to a backend
    # @schema
    timeout: 5s
    # @schema
    # description: Configuration for retry on failure.
    # @schema
    retryOnFailure:
      # @schema
      # description: Whether to retry on failure, by default it is enabled.
      # @schema
      enabled: true
      # @schema
      # description: Time to wait after the first failure before retrying; ignored if `enabled` is `false`.
      # @schema
      initialInterval: 5s
      # @schema
      # description: Is the upper bound on backoff; ignored if `enabled` is `false`.
      # @schema
      maxInterval: 30s
      # @schema
      # description: |-
      #   Is the maximum amount of time spent trying to send a batch; ignored if `enabled` is `false`.
      #   If set to 0, the retry will continue indefinitely until the data is sent successfully.
      # @schema
      maxElapsedTime: 300s

  # @schema
  # description: |-
  #   RequestMemoryMiB is the memory request for the node collector daemonset.
  #   it will be embedded in the daemonset as a resource request of the form "memory: <value>Mi"
  #   default value is 250Mi
  #   If you set only requestMemoryMiB, the limitMemoryMiB will be set to the same value.
  # @schema
  # requestMemoryMiB: 250

  # @schema
  # description: |-
  #   LimitMemoryMiB is the memory limit for the node collector daemonset.
  #   it will be embedded in the daemonset as a resource limit of the form "memory: <value>Mi"
  #   default value is 500Mi
  #   If you set only limitMemoryMiB, the requestMemoryMiB will be set to the same value.
  # @schema
  # limitMemoryMiB: 500

  # @schema
  # description: |-
  #   the CPU request for the node collector daemonset.
  #   it will be embedded in the daemonset as a resource request
  #   of the form "cpu: <value>m".
  #   default value is 250m
  #   If you set only requestCPUm, the limitCPUm will be set to the same value.
  # @schema
  # requestCPUm: 250

  # @schema
  # description: |-
  #   the CPU limit for the node collector daemonset.
  #   it will be embedded in the daemonset as a resource limit
  #   of the form "cpu: <value>m".
  #   default value is 500m
  #   If you set only limitCPUm, the requestCPUm will be set to the same value.
  # @schema
  # limitCPUm: 500

  # @schema
  # description: |-
  #   this parameter sets the "limit_mib" parameter in the memory limiter configuration for the node collector.
  #   it is the hard limit after which a force garbage collection will be performed.
  #   if not set, it will be 50Mi below the memory limit.
  # @schema
  # memoryLimiterLimitMiB: 450

  # @schema
  # description: |-
  #   this parameter sets the "spike_limit_mib" parameter in the memory limiter configuration for the node collector.
  #   note that this is not the processor soft limit, but the diff in Mib between the hard limit and the soft limit.
  #   if not set, this will be set to 20% of the hard limit (so the soft limit will be 80% of the hard limit).
  # @schema
  # memoryLimiterSpikeLimitMiB: 90

  # @schema
  # description: |-
  #   the GOMEMLIMIT environment variable value for the node collector daemonset.
  #   this is when go runtime will start garbage collection.
  #   if not specified, it will be set to 80% of the hard limit of the memory limiter.
  # @schema
  # goMemLimitMiB: 360

# @schema
# description: Configuration for the autoscaler component.
# @schema
autoscaler:
  # @schema
  # description: |-
  #   tolerations for the autoscaler deployment.
  # @schema
  tolerations: []

  # @schema
  # description: |-
  #   affinity for the autoscaler deployment.
  # @schema
  affinity: {}

  # @schema
  # description: |-
  #   resources for the autoscaler deployment.
  # @schema
  resources:
    requests:
      cpu: 10m
      memory: 64Mi
    limits:
      cpu: 500m
      memory: 512Mi

  # @schema
  # description: Uncomment to override the global nodeSelector (values.nodeSelector) for this component
  # @schema
  # nodeSelector:
  #   kubernetes.io/os: linux

  # @schema
  # description: Priority class name. Set to use your existing cluster priority classes.
  # @schema
  # priorityClassName: ''

# @schema
# description: Configuration for the scheduler component.
# @schema
scheduler:
  # @schema
  # description: |-
  #   tolerations for the scheduler deployment.
  # @schema
  tolerations: []

  # @schema
  # description: |-
  #   affinity for the scheduler deployment.
  # @schema
  affinity: {}

  # @schema
  # description: |-
  #   resources for the scheduler deployment.
  # @schema
  resources:
    requests:
      cpu: 10m
      memory: 64Mi
    limits:
      cpu: 500m
      memory: 512Mi

  # @schema
  # description: Uncomment to override the global nodeSelector (values.nodeSelector) for this component
  # @schema
  # nodeSelector:
  #   kubernetes.io/os: linux
  
  # @schema
  # description: Priority class name. Set to use your existing cluster priority classes.
  # @schema
  # priorityClassName: ''

# @schema
# description: Configuration for the UI component.
# @schema
ui:
  # @schema
  # description: Uncomment to override the global nodeSelector (values.nodeSelector) for this component
  # @schema
  # nodeSelector:
  #   kubernetes.io/os: linux
  tolerations: []
  affinity: {}
  resources:
    requests:
      cpu: 10m
      memory: 64Mi
    limits:
      cpu: 500m
      memory: 512Mi

  # @schema
  # description: |-
  #   uiMode: 'default' or 'readonly'
  #    - This flag controls whether the UI should be in read-only mode.
  #    - Setting this to "readonly" will disable the ability to create, update, or delete objects in the UI.
  #    - If not set, the UI will be in default mode.
  # @schema
  uiMode: 'default'

  # @schema
  # description: |-
  #   uiPaginationLimit:
  #    - This flag controls the number of items to fetch per paginated-batch in the UI.
  #    - If not set, the UI will fetch 100 items per paginated-batch.
  # @schema

  uiPaginationLimit: 0
  # @schema
  # description: |-
  #   uiRemoteUrl:
  #    - This flag sets the URL of the remote UI (e.g. https://my-odigos-ui.com).
  #    - If not set, the UI will default to the local UI.
  #    - This is useful when you are hosting the Odigos UI on a custom/remote URL, and require OIDC authentication.
  # @schema

  uiRemoteUrl: ''
  # @schema
  # description: |-
  #   oidcTenantUrl:
  #    - This flag sets the URL of the OIDC tenant (e.g. https://my-oidc-tenant.com).
  #    - If not set, the UI will not process OIDC authentication.
  # @schema

  oidcTenantUrl: ''
  # @schema
  # description: |-
  #   oidcClientId:
  #    - This flag sets the client ID of the OIDC application.
  #    - If not set, the UI will not process OIDC authentication.
  # @schema

  oidcClientId: ''
  # @schema
  # description: |-
  #   oidcClientSecret:
  #    - This flag sets the client secret of the OIDC application.
  #    - If not set, the UI will not process OIDC authentication.
  # @schema

  # @schema
  # description: |-
  #   oidcClientSecret:
  #    - This flag sets the client secret of the OIDC application.
  #    - If not set, the UI will not process OIDC authentication.
  # @schema
  oidcClientSecret: ''

  # @schema
  # description: |-
  #   centralBackendURL:
  #    - This flag sets the URL of the central backend.
  #    - If not set, the UI will not connect to the central backend.
  # @schema
  centralBackendURL: ''

  # @schema
  # description: Priority class name. Set to use your existing cluster priority classes.
  # @schema
  # priorityClassName: ''

# @schema
# description: Configuration for the instrumentor component.
# @schema
instrumentor:

  # @schema
  # description: |-
  #   which mount method to use for odigos agent directory
  #   k8s-virtual-device: default method using a virtual device
  #   k8s-host-path: alternative which uses hostPath volume (recommended if supported, requires hostPath volume to be enabled in the cluster)
  #   k8s-init-container: alternative which uses an init container to copy the agent files to the shared volume
  # @schema
  mountMethod: ''

  # @schema
  # description: |-
  #   checkDeviceHealthBeforeInjection is relevant only when mountMethod is k8s-virtual-device.
  #   before injecting odigos agent into a new pod, it will check that all odiglet "deviceplugin"
  #   containers are not in crash loop backoff.
  #   this is to avoid adding a device (as resource request on a container)
  #   where an odiglet might not be able to provide the device on the node and fail k8s scheduling for instrumented pods on all nodes.
  # @schema
  checkDeviceHealthBeforeInjection: false

  # @schema
  # description: |-
  #   Resource configuration for the init container that is injected into user pods
  #   when using the k8s-init-container mount method.
  #   The init container is responsible for copying the instrumentation agents to the shared volume.
  # @schema
  agentsInitContainerResources:
    requests:
      cpu: 300m
      memory: 300Mi
    limits:
      cpu: 300m
      memory: 300Mi

  # @schema
  # description: |-
  #   tolerations for the instrumentor deployment.
  # @schema
  tolerations: []

  # @schema
  # description: |-
  #   affinity for the instrumentor deployment.
  # @schema
  affinity: {}

  # @schema
  # description: |-
  #   resources for the instrumentor deployment.
  # @schema
  resources:
    requests:
      cpu: 10m
      memory: 64Mi
    limits:
      cpu: 500m
      memory: 512Mi

  # @schema
  # description: |-
  #   how to add the required environment variables for instrumentation to a container
  #   loader: only try using the odigos loader which requires setting the LD_PRELOAD env var in the container manifest.
  #   pod-manifest: add the environment variables to the container manifest.
  #   loader-fallback-to-pod-manifest: try using the odigos loader first, and if it fails, fallback to adding the environment variables to the container manifest.
  # @schema
  agentEnvVarsInjectionMethod: ''

  # @schema
  # description: |-
  #   the timeout in seconds for the pods webhook.
  #   default is 10 seconds and it is recommended to keep it as is unless you are experiencing issues with the webhook.
  #   value must be 30 seconds max (inforced by kubernetes)
  #   a shorter timeout will relieve API pressure, but may result in more pods failing to instrument
  # @schema
  # podsWebhookTimeoutSeconds: 25

  # @schema
  # description: Uncomment to override the global nodeSelector (values.nodeSelector) for this component
  # @schema
  # nodeSelector:
  #   kubernetes.io/os: linux

  # @schema
  # description: Priority class name. Set to use your existing cluster priority classes.
  # @schema
  # priorityClassName: ''
